# DNN_parallelism
This project explores different forms of parallelism available in DNN Training phase.

Reference Links:
1. http://www.deepideas.net/deep-learning-from-scratch-i-computational-graphs/
2. https://ebookcentral.proquest.com/lib/UTXA/detail.action?docID=5314509
3. https://medium.com/tebs-lab/deep-neural-networks-as-computational-graphs-867fcaa56c9
4. https://medium.com/syncedreview/how-to-train-a-very-large-and-deep-model-on-one-gpu-7b7edfe2d072
5. https://medium.com/coinmonks/understand-alexnet-in-just-3-minutes-with-hands-on-code-using-tensorflow-925d1e2e2f82
6. https://arxiv.org/pdf/1410.0759.pdf
7. https://svail.github.io/DeepBench/
8. https://www2.seas.gwu.edu/~howie/publications/GPU-CNN-ICPP16.pdf
9. https://arxiv.org/pdf/1501.06633.pdf
10. https://arxiv.org/pdf/1807.01702.pdf
11. https://www.sysml.cc/doc/2019/69.pdf
12. https://arxiv.org/pdf/1804.04806.pdf
13. http://people.bu.edu/joshi/files/evaluation-multi-gpu-iiswc-2018.pdf
